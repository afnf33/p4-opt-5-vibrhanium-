# Anchor
lr_low      : &lr_low     0.001
lr_high     : &lr_high    0.001
beta1_low   : &beta1_low  0.9
beta1_high  : &beta1_high 0.9
beta2_low   : &beta2_low  0.999
beta2_high  : &beta2_high 0.999
weight_decay_low  : &weight_decay_low   0.01
weight_decay_high : &weight_decay_high  0.01


# optimizer config
Adam:
  lr     :
    name : learning_rate
    type : float
    low  : *lr_low
    high : *lr_high

  beta1  :
    name : beta1
    type : float
    low  : *beta1_low
    high : *beta1_high

  beta2  :
    name : beta2
    type : float
    low  : *beta2_low
    high : *beta2_high

AdamW:
  lr     : 
    name : learning_rate
    type : float
    low  : *lr_low
    high : *lr_high

  beta1  :
    name : beta1
    type : float
    low  : *beta1_low
    high : *beta1_high

  beta2  :
    name : beta2
    type : float
    low  : *beta2_low
    high : *beta2_high
  
  eps   :
    name : eps
    type : float
    low  : 0.00000008
    high : 0.00000008

  weight_decay:
    name  : weight_decay
    type  : float
    low  : *weight_decay_low
    high : *weight_decay_high

  amsgrad   :
    name  : amsgrad
    type  : int
    low   : 0  # False
    high  : 0  # Fasle

SGD: 
  lr     :
        name : learning_rate
        type : float
        low   : *lr_low
        high  : *lr_high
