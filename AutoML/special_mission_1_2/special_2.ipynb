{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e72cffd-fa23-45b3-af3c-7eae6ef7adaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.2 MB 825 kB/s eta 0:00:01    |████████████████▌               | 6.8 MB 7.7 MB/s eta 0:00:01     |███████████████████             | 7.8 MB 7.7 MB/s eta 0:00:01     |███████████████████████████████ | 12.8 MB 7.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /miniconda/lib/python3.8/site-packages (from plotly) (1.3.3)\n",
      "Requirement already satisfied: six in /miniconda/lib/python3.8/site-packages (from plotly) (1.16.0)\n",
      "Installing collected packages: plotly\n",
      "Successfully installed plotly-4.14.3\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe0ecfa-9738-45c5-9369-d6373469725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import thop # MACs, FLop 수 측정 \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f916d131-af08-4f6a-a0b8-1e13244ad7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_class = 10\n",
    "\n",
    "LOG_INTERVAL = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "083e003c-dfc5-4dde-9da4-7afa231e02c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "    \n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(f\"n_units_l{i}\", 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(f\"dropout_l{i}\", 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "        \n",
    "        in_features = out_features\n",
    "\n",
    "    layers.append(nn.Linear(in_features, num_class))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "    \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ecf9615-4be8-4377-b5e7-ad4de468163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size):\n",
    "    train_dataset = datasets.FashionMNIST('./cifar10/', train=True, download=True, transform=transforms.ToTensor())\n",
    "    valid_dataset = datasets.FashionMNIST('./cifar10/', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf7c5d9c-f73a-44b9-ac5c-a3063be6db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, epoch, batch_size):\n",
    "    model.train()\n",
    "    for batch_idx, (X_train, y_train) in enumerate(train_loader):\n",
    "        X_train = X_train.view(X_train.size(0), -1).to(device)\n",
    "        y_train = y_train.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = F.nll_loss(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{(batch_idx + 1) * batch_size}/{len(train_loader.dataset)}]\\tLoss: {loss.item():.6f}\")\n",
    "            \n",
    "def evaluation(model, valid_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X_valid, y_valid) in enumerate(valid_loader):\n",
    "            X_valid = X_valid.view(X_valid.size(0), -1).to(device)\n",
    "            y_valid = y_valid.to(device)\n",
    "\n",
    "            output = model(X_valid)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(y_valid.view_as(pred)).sum().item()\n",
    "\n",
    "    accuracy = correct / len(valid_loader.dataset)\n",
    "\n",
    "    flops, _ = thop.profile(model, inputs=(torch.randn(1, 28 * 28).to(device),), verbose=False)\n",
    "\n",
    "    return flops, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cbf0f4b-3204-472b-bb7c-7e05d56c541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    model = define_model(trial).to(device)\n",
    "    \n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])\n",
    "    \n",
    "    train_loader, valid_loader = get_dataloader(batch_size)\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        train(model, optimizer, train_loader, epoch + 1, batch_size)\n",
    "    flops, accuracy = evaluation(model, valid_loader)\n",
    "    \n",
    "    return flops, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b770d02-00fb-4db5-a154-48fc5999a747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-27 11:23:14,621]\u001b[0m A new study created in memory with name: no-name-5dfdceca-7a48-4974-9033-2ff4b7197169\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [8/60000]\tLoss: 2.333590\n",
      "Train Epoch: 1 [4808/60000]\tLoss: 1.422965\n",
      "Train Epoch: 1 [9608/60000]\tLoss: 1.859233\n",
      "Train Epoch: 1 [14408/60000]\tLoss: 1.420964\n",
      "Train Epoch: 1 [19208/60000]\tLoss: 2.260689\n",
      "Train Epoch: 1 [24008/60000]\tLoss: 2.032409\n",
      "Train Epoch: 1 [28808/60000]\tLoss: 1.504974\n",
      "Train Epoch: 1 [33608/60000]\tLoss: 1.789898\n",
      "Train Epoch: 1 [38408/60000]\tLoss: 2.019917\n",
      "Train Epoch: 1 [43208/60000]\tLoss: 1.843495\n",
      "Train Epoch: 1 [48008/60000]\tLoss: 2.021448\n",
      "Train Epoch: 1 [52808/60000]\tLoss: 1.846212\n",
      "Train Epoch: 1 [57608/60000]\tLoss: 1.876760\n",
      "Train Epoch: 2 [8/60000]\tLoss: 1.617670\n",
      "Train Epoch: 2 [4808/60000]\tLoss: 2.374501\n",
      "Train Epoch: 2 [9608/60000]\tLoss: 1.942030\n",
      "Train Epoch: 2 [14408/60000]\tLoss: 1.708834\n",
      "Train Epoch: 2 [19208/60000]\tLoss: 1.605093\n",
      "Train Epoch: 2 [24008/60000]\tLoss: 1.818170\n",
      "Train Epoch: 2 [28808/60000]\tLoss: 1.787366\n",
      "Train Epoch: 2 [33608/60000]\tLoss: 1.991976\n",
      "Train Epoch: 2 [38408/60000]\tLoss: 1.641342\n",
      "Train Epoch: 2 [43208/60000]\tLoss: 1.772716\n",
      "Train Epoch: 2 [48008/60000]\tLoss: 1.798266\n",
      "Train Epoch: 2 [52808/60000]\tLoss: 1.660329\n",
      "Train Epoch: 2 [57608/60000]\tLoss: 1.893482\n",
      "Train Epoch: 3 [8/60000]\tLoss: 1.731897\n",
      "Train Epoch: 3 [4808/60000]\tLoss: 1.522992\n",
      "Train Epoch: 3 [9608/60000]\tLoss: 1.574595\n",
      "Train Epoch: 3 [14408/60000]\tLoss: 2.058924\n",
      "Train Epoch: 3 [19208/60000]\tLoss: 1.691546\n",
      "Train Epoch: 3 [24008/60000]\tLoss: 1.794877\n",
      "Train Epoch: 3 [28808/60000]\tLoss: 1.993526\n",
      "Train Epoch: 3 [33608/60000]\tLoss: 1.860128\n",
      "Train Epoch: 3 [38408/60000]\tLoss: 1.947818\n",
      "Train Epoch: 3 [43208/60000]\tLoss: 2.027444\n",
      "Train Epoch: 3 [48008/60000]\tLoss: 1.861744\n",
      "Train Epoch: 3 [52808/60000]\tLoss: 2.295193\n",
      "Train Epoch: 3 [57608/60000]\tLoss: 2.479302\n",
      "Train Epoch: 4 [8/60000]\tLoss: 2.126966\n",
      "Train Epoch: 4 [4808/60000]\tLoss: 1.851604\n",
      "Train Epoch: 4 [9608/60000]\tLoss: 2.351884\n",
      "Train Epoch: 4 [14408/60000]\tLoss: 1.888385\n",
      "Train Epoch: 4 [19208/60000]\tLoss: 1.713159\n",
      "Train Epoch: 4 [24008/60000]\tLoss: 2.034915\n",
      "Train Epoch: 4 [28808/60000]\tLoss: 1.809665\n",
      "Train Epoch: 4 [33608/60000]\tLoss: 1.929722\n",
      "Train Epoch: 4 [38408/60000]\tLoss: 1.846664\n",
      "Train Epoch: 4 [43208/60000]\tLoss: 3.051728\n",
      "Train Epoch: 4 [48008/60000]\tLoss: 1.920483\n",
      "Train Epoch: 4 [52808/60000]\tLoss: 1.925665\n",
      "Train Epoch: 4 [57608/60000]\tLoss: 1.778142\n",
      "Train Epoch: 5 [8/60000]\tLoss: 1.918421\n",
      "Train Epoch: 5 [4808/60000]\tLoss: 1.692308\n",
      "Train Epoch: 5 [9608/60000]\tLoss: 2.102375\n",
      "Train Epoch: 5 [14408/60000]\tLoss: 2.487811\n",
      "Train Epoch: 5 [19208/60000]\tLoss: 1.477502\n",
      "Train Epoch: 5 [24008/60000]\tLoss: 1.789166\n",
      "Train Epoch: 5 [28808/60000]\tLoss: 1.721558\n",
      "Train Epoch: 5 [33608/60000]\tLoss: 2.054414\n",
      "Train Epoch: 5 [38408/60000]\tLoss: 1.782048\n",
      "Train Epoch: 5 [43208/60000]\tLoss: 1.721324\n",
      "Train Epoch: 5 [48008/60000]\tLoss: 2.106283\n",
      "Train Epoch: 5 [52808/60000]\tLoss: 2.253722\n",
      "Train Epoch: 5 [57608/60000]\tLoss: 2.016882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-27 11:25:31,021]\u001b[0m Trial 0 finished with values: [73860.0, 0.1974] and parameters: {'n_layers': 2, 'n_units_l0': 90, 'dropout_l0': 0.28474486906122964, 'n_units_l1': 33, 'dropout_l1': 0.3052251910646641, 'optimizer': 'Adam', 'lr': 0.02536785489117226, 'batch_size': 8}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [16/60000]\tLoss: 2.298073\n",
      "Train Epoch: 1 [9616/60000]\tLoss: 2.315526\n",
      "Train Epoch: 1 [19216/60000]\tLoss: 2.313309\n",
      "Train Epoch: 1 [28816/60000]\tLoss: 2.290269\n",
      "Train Epoch: 1 [38416/60000]\tLoss: 2.285532\n",
      "Train Epoch: 1 [48016/60000]\tLoss: 2.315760\n",
      "Train Epoch: 1 [57616/60000]\tLoss: 2.357987\n",
      "Train Epoch: 2 [16/60000]\tLoss: 2.298936\n",
      "Train Epoch: 2 [9616/60000]\tLoss: 2.304021\n",
      "Train Epoch: 2 [19216/60000]\tLoss: 2.235815\n",
      "Train Epoch: 2 [28816/60000]\tLoss: 2.332672\n",
      "Train Epoch: 2 [38416/60000]\tLoss: 2.327435\n",
      "Train Epoch: 2 [48016/60000]\tLoss: 2.311598\n",
      "Train Epoch: 2 [57616/60000]\tLoss: 2.288959\n",
      "Train Epoch: 3 [16/60000]\tLoss: 2.300531\n",
      "Train Epoch: 3 [9616/60000]\tLoss: 2.313642\n",
      "Train Epoch: 3 [19216/60000]\tLoss: 2.364559\n",
      "Train Epoch: 3 [28816/60000]\tLoss: 2.330896\n",
      "Train Epoch: 3 [38416/60000]\tLoss: 2.282769\n",
      "Train Epoch: 3 [48016/60000]\tLoss: 2.273722\n",
      "Train Epoch: 3 [57616/60000]\tLoss: 2.305043\n",
      "Train Epoch: 4 [16/60000]\tLoss: 2.294547\n",
      "Train Epoch: 4 [9616/60000]\tLoss: 2.339313\n",
      "Train Epoch: 4 [19216/60000]\tLoss: 2.318182\n",
      "Train Epoch: 4 [28816/60000]\tLoss: 2.277166\n",
      "Train Epoch: 4 [38416/60000]\tLoss: 2.316298\n",
      "Train Epoch: 4 [48016/60000]\tLoss: 2.272427\n",
      "Train Epoch: 4 [57616/60000]\tLoss: 2.271272\n",
      "Train Epoch: 5 [16/60000]\tLoss: 2.323696\n",
      "Train Epoch: 5 [9616/60000]\tLoss: 2.336848\n",
      "Train Epoch: 5 [19216/60000]\tLoss: 2.316883\n",
      "Train Epoch: 5 [28816/60000]\tLoss: 2.313758\n",
      "Train Epoch: 5 [38416/60000]\tLoss: 2.300181\n",
      "Train Epoch: 5 [48016/60000]\tLoss: 2.327254\n",
      "Train Epoch: 5 [57616/60000]\tLoss: 2.312299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-27 11:26:33,265]\u001b[0m Trial 1 finished with values: [16260.0, 0.1219] and parameters: {'n_layers': 3, 'n_units_l0': 6, 'dropout_l0': 0.2181598737427078, 'n_units_l1': 78, 'dropout_l1': 0.3278983383803069, 'n_units_l2': 126, 'dropout_l2': 0.25477744101607314, 'optimizer': 'SGD', 'lr': 3.6418976146596215e-05, 'batch_size': 16}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [16/60000]\tLoss: 2.293696\n",
      "Train Epoch: 1 [9616/60000]\tLoss: 1.728570\n",
      "Train Epoch: 1 [19216/60000]\tLoss: 1.473711\n",
      "Train Epoch: 1 [28816/60000]\tLoss: 1.742243\n",
      "Train Epoch: 1 [38416/60000]\tLoss: 1.520983\n",
      "Train Epoch: 1 [48016/60000]\tLoss: 1.681353\n",
      "Train Epoch: 1 [57616/60000]\tLoss: 1.362257\n",
      "Train Epoch: 2 [16/60000]\tLoss: 1.682393\n",
      "Train Epoch: 2 [9616/60000]\tLoss: 1.589703\n",
      "Train Epoch: 2 [19216/60000]\tLoss: 1.218444\n",
      "Train Epoch: 2 [28816/60000]\tLoss: 1.335213\n",
      "Train Epoch: 2 [38416/60000]\tLoss: 1.800051\n",
      "Train Epoch: 2 [48016/60000]\tLoss: 1.412847\n",
      "Train Epoch: 2 [57616/60000]\tLoss: 2.137013\n",
      "Train Epoch: 3 [16/60000]\tLoss: 1.005569\n",
      "Train Epoch: 3 [9616/60000]\tLoss: 1.661849\n",
      "Train Epoch: 3 [19216/60000]\tLoss: 0.844988\n",
      "Train Epoch: 3 [28816/60000]\tLoss: 1.771790\n",
      "Train Epoch: 3 [38416/60000]\tLoss: 1.360049\n",
      "Train Epoch: 3 [48016/60000]\tLoss: 1.248000\n",
      "Train Epoch: 3 [57616/60000]\tLoss: 0.994211\n",
      "Train Epoch: 4 [16/60000]\tLoss: 1.383453\n",
      "Train Epoch: 4 [9616/60000]\tLoss: 1.387436\n",
      "Train Epoch: 4 [19216/60000]\tLoss: 1.209008\n",
      "Train Epoch: 4 [28816/60000]\tLoss: 1.400251\n",
      "Train Epoch: 4 [38416/60000]\tLoss: 1.084523\n",
      "Train Epoch: 4 [48016/60000]\tLoss: 1.285230\n",
      "Train Epoch: 4 [57616/60000]\tLoss: 1.021295\n",
      "Train Epoch: 5 [16/60000]\tLoss: 0.707867\n",
      "Train Epoch: 5 [9616/60000]\tLoss: 0.882043\n",
      "Train Epoch: 5 [19216/60000]\tLoss: 1.391219\n",
      "Train Epoch: 5 [28816/60000]\tLoss: 1.050874\n",
      "Train Epoch: 5 [38416/60000]\tLoss: 1.167807\n",
      "Train Epoch: 5 [48016/60000]\tLoss: 1.526786\n",
      "Train Epoch: 5 [57616/60000]\tLoss: 0.977307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-27 11:27:20,985]\u001b[0m Trial 2 finished with values: [7146.0, 0.7683] and parameters: {'n_layers': 1, 'n_units_l0': 9, 'dropout_l0': 0.3939165575767588, 'optimizer': 'SGD', 'lr': 0.0037790183104091974, 'batch_size': 16}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [32/60000]\tLoss: 2.310396\n",
      "Train Epoch: 1 [19232/60000]\tLoss: 1.438598\n",
      "Train Epoch: 1 [38432/60000]\tLoss: 0.998718\n",
      "Train Epoch: 1 [57632/60000]\tLoss: 1.199026\n",
      "Train Epoch: 2 [32/60000]\tLoss: 0.714622\n",
      "Train Epoch: 2 [19232/60000]\tLoss: 1.268554\n",
      "Train Epoch: 2 [38432/60000]\tLoss: 1.069105\n",
      "Train Epoch: 2 [57632/60000]\tLoss: 1.062551\n",
      "Train Epoch: 3 [32/60000]\tLoss: 0.735945\n",
      "Train Epoch: 3 [19232/60000]\tLoss: 1.023360\n",
      "Train Epoch: 3 [38432/60000]\tLoss: 0.736868\n",
      "Train Epoch: 3 [57632/60000]\tLoss: 0.749549\n",
      "Train Epoch: 4 [32/60000]\tLoss: 0.973790\n",
      "Train Epoch: 4 [19232/60000]\tLoss: 0.960187\n",
      "Train Epoch: 4 [38432/60000]\tLoss: 0.894830\n",
      "Train Epoch: 4 [57632/60000]\tLoss: 0.804812\n",
      "Train Epoch: 5 [32/60000]\tLoss: 1.188487\n",
      "Train Epoch: 5 [19232/60000]\tLoss: 1.026403\n",
      "Train Epoch: 5 [38432/60000]\tLoss: 0.891758\n",
      "Train Epoch: 5 [57632/60000]\tLoss: 0.965979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-27 11:28:03,206]\u001b[0m Trial 3 finished with values: [30024.0, 0.746] and parameters: {'n_layers': 3, 'n_units_l0': 30, 'dropout_l0': 0.4362449644849893, 'n_units_l1': 74, 'dropout_l1': 0.26511731142938555, 'n_units_l2': 51, 'dropout_l2': 0.2865670114680688, 'optimizer': 'Adam', 'lr': 0.00660398163203898, 'batch_size': 32}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [8/60000]\tLoss: 2.305089\n",
      "Train Epoch: 1 [4808/60000]\tLoss: 2.327289\n",
      "Train Epoch: 1 [9608/60000]\tLoss: 2.317467\n",
      "Train Epoch: 1 [14408/60000]\tLoss: 2.290693\n",
      "Train Epoch: 1 [19208/60000]\tLoss: 2.309203\n",
      "Train Epoch: 1 [24008/60000]\tLoss: 2.322999\n",
      "Train Epoch: 1 [28808/60000]\tLoss: 2.285873\n",
      "Train Epoch: 1 [33608/60000]\tLoss: 2.297134\n",
      "Train Epoch: 1 [38408/60000]\tLoss: 2.252794\n",
      "Train Epoch: 1 [43208/60000]\tLoss: 2.345644\n",
      "Train Epoch: 1 [48008/60000]\tLoss: 2.331042\n",
      "Train Epoch: 1 [52808/60000]\tLoss: 2.292424\n",
      "Train Epoch: 1 [57608/60000]\tLoss: 2.317260\n",
      "Train Epoch: 2 [8/60000]\tLoss: 2.317501\n",
      "Train Epoch: 2 [4808/60000]\tLoss: 2.337159\n",
      "Train Epoch: 2 [9608/60000]\tLoss: 2.299973\n",
      "Train Epoch: 2 [14408/60000]\tLoss: 2.276523\n",
      "Train Epoch: 2 [19208/60000]\tLoss: 2.268690\n",
      "Train Epoch: 2 [24008/60000]\tLoss: 2.307907\n",
      "Train Epoch: 2 [28808/60000]\tLoss: 2.321126\n",
      "Train Epoch: 2 [33608/60000]\tLoss: 2.287346\n",
      "Train Epoch: 2 [38408/60000]\tLoss: 2.299551\n",
      "Train Epoch: 2 [43208/60000]\tLoss: 2.332596\n",
      "Train Epoch: 2 [48008/60000]\tLoss: 2.314200\n",
      "Train Epoch: 2 [52808/60000]\tLoss: 2.293609\n",
      "Train Epoch: 2 [57608/60000]\tLoss: 2.291107\n",
      "Train Epoch: 3 [8/60000]\tLoss: 2.339355\n",
      "Train Epoch: 3 [4808/60000]\tLoss: 2.293380\n",
      "Train Epoch: 3 [9608/60000]\tLoss: 2.355811\n",
      "Train Epoch: 3 [14408/60000]\tLoss: 2.296133\n",
      "Train Epoch: 3 [19208/60000]\tLoss: 2.293470\n",
      "Train Epoch: 3 [24008/60000]\tLoss: 2.297710\n",
      "Train Epoch: 3 [28808/60000]\tLoss: 2.306614\n",
      "Train Epoch: 3 [33608/60000]\tLoss: 2.304683\n",
      "Train Epoch: 3 [38408/60000]\tLoss: 2.267521\n",
      "Train Epoch: 3 [43208/60000]\tLoss: 2.326985\n",
      "Train Epoch: 3 [48008/60000]\tLoss: 2.260149\n",
      "Train Epoch: 3 [52808/60000]\tLoss: 2.258162\n",
      "Train Epoch: 3 [57608/60000]\tLoss: 2.288439\n",
      "Train Epoch: 4 [8/60000]\tLoss: 2.273925\n",
      "Train Epoch: 4 [4808/60000]\tLoss: 2.296447\n",
      "Train Epoch: 4 [9608/60000]\tLoss: 2.240628\n",
      "Train Epoch: 4 [14408/60000]\tLoss: 2.279730\n",
      "Train Epoch: 4 [19208/60000]\tLoss: 2.312834\n",
      "Train Epoch: 4 [24008/60000]\tLoss: 2.301389\n",
      "Train Epoch: 4 [28808/60000]\tLoss: 2.285012\n",
      "Train Epoch: 4 [33608/60000]\tLoss: 2.331275\n",
      "Train Epoch: 4 [38408/60000]\tLoss: 2.284456\n",
      "Train Epoch: 4 [43208/60000]\tLoss: 2.303142\n",
      "Train Epoch: 4 [48008/60000]\tLoss: 2.311355\n",
      "Train Epoch: 4 [52808/60000]\tLoss: 2.320080\n",
      "Train Epoch: 4 [57608/60000]\tLoss: 2.259837\n",
      "Train Epoch: 5 [8/60000]\tLoss: 2.283634\n",
      "Train Epoch: 5 [4808/60000]\tLoss: 2.326493\n",
      "Train Epoch: 5 [9608/60000]\tLoss: 2.335639\n",
      "Train Epoch: 5 [14408/60000]\tLoss: 2.289442\n",
      "Train Epoch: 5 [19208/60000]\tLoss: 2.315681\n",
      "Train Epoch: 5 [24008/60000]\tLoss: 2.272179\n",
      "Train Epoch: 5 [28808/60000]\tLoss: 2.290405\n",
      "Train Epoch: 5 [33608/60000]\tLoss: 2.302579\n",
      "Train Epoch: 5 [38408/60000]\tLoss: 2.289426\n",
      "Train Epoch: 5 [43208/60000]\tLoss: 2.235975\n",
      "Train Epoch: 5 [48008/60000]\tLoss: 2.308292\n",
      "Train Epoch: 5 [52808/60000]\tLoss: 2.289394\n",
      "Train Epoch: 5 [57608/60000]\tLoss: 2.287490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-27 11:30:02,603]\u001b[0m Trial 4 finished with values: [36948.0, 0.1134] and parameters: {'n_layers': 3, 'n_units_l0': 43, 'dropout_l0': 0.22017759078832386, 'n_units_l1': 29, 'dropout_l1': 0.4249698373164872, 'n_units_l2': 51, 'dropout_l2': 0.4442886436114746, 'optimizer': 'SGD', 'lr': 1.799256274814117e-05, 'batch_size': 8}. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  5\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(directions=[\"minimize\", \"maximize\"])\n",
    "study.optimize(objective, n_trials=30, timeout=300)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf47a013-e384-488a-bacb-0fb691a2be87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-17920863a436>:1: ExperimentalWarning: plot_pareto_front is experimental (supported from v2.4.0). The interface can change in the future.\n",
      "  optuna.visualization.plot_pareto_front(study, target_names=[\"FLOPS\", \"accuracy\"])\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/miniconda/lib/python3.8/site-packages/optuna/visualization/_plotly_imports.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtry_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_imports\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplotly_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-17920863a436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_pareto_front\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FLOPS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/miniconda/lib/python3.8/site-packages/optuna/_experimental.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 )\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.8/site-packages/optuna/visualization/_pareto_front.py\u001b[0m in \u001b[0;36mplot_pareto_front\u001b[0;34m(study, target_names, include_dominated_trials, axis_order)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0m_imports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirections\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/lib/python3.8/site-packages/optuna/_imports.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deferred\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deferred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "optuna.visualization.plot_pareto_front(study, target_names=[\"FLOPS\", \"accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
